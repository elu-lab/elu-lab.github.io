@inproceedings{lak2018,
    author = {Kim, Bugeun and Rhim, Jungwook and Rho, Jihyun and Hwang, Taehyun and Lee, Gunho and Gweon, Gahgene},
    title = {"I'll Do It!": Examining the Relationship between Locus of Control and Math Game Retention for Preschoolers},
    year = {2018},
    month = {March},
    isbn = {9781450364003},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3170358.3170368},
    doi = {10.1145/3170358.3170368},
    lang = en,
    abstract = {Acquiring simple arithmetic skills at the preschool level requires repetitive practices. One method for encouraging students to spend longer time practicing is by presenting the skills in an engaging game. As student retention on the game increases, the student will be more likely to acquire the practiced skill since she will have spent more time practicing. In this paper, we examine the relationship between internal locus of control and retention in game-based learning applications for young children using Todo Math, a mobile-based math learning application for children from Pre-K to 2nd grade. We examine 345,783 users' log data to show that when children prefer "free" mode, which has high internal locus of control, their retention on Todo Math is higher than children who prefer "daily" mode, which has high external locus of control. We present three analyses that support our findings using survival analysis, post-hoc analysis, and t-test.},
    booktitle = {Proceedings of the 8th International Conference on Learning Analytics and Knowledge ({LAK})},
    pages = {290–294},
    numpages = {5},
    keywords = {preschooler, retention, locus of control, online math game},
    location = {Sydney, New South Wales, Australia},
    series = {LAK '18},
    note = {#Application:Education},
}

@inproceedings{mable,
    author = {Gweon, Gahgene and Kim, Bugeun and Kim, Jinyoung and Lee, Kung Jin and Rhim, Jungwook and Choi, Jueun},
    title = {MABLE: Mediating Young Children's Smart Media Usage with Augmented Reality},
    year = {2018},
    month = {April},
    isbn = {9781450356206},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3173574.3173587},
    doi = {10.1145/3173574.3173587},
    lang = en,
    abstract = {There has been a growing concern over the huge increase in use of smart media by young children. This study explores the possibility of using augmented-reality(AR) for regulat-ing preschoolers' media usage behavior. With MABLE (mobile application for behavioral learning and education), parents can provide AR-assisted feedback by changing facial expressions and sound effects. When overlaying a smart media, which has MABLE running, in front of a QR marker on a puppet, a facial expression is displayed on top of the puppet's face. A two-week long experiment with 36 parent-child pairs showed that compared to using just the puppet, using MABLE showed higher amount of engage-ment among preschoolers. For the effectiveness of parental mediation in terms of self-control, our data showed mixed results. MABLE had positive effects in that the amount of rule-compliance increased and problematic behaviors de-creased, whereas the level of behavioral dependency on smart media was not influenced.},
    booktitle = {Proceedings of the 2018 {CHI} Conference on Human Factors in Computing Systems},
    pages = {1–9},
    numpages = {9},
    series = {CHI '18},
    note = {#BK21TopConf #HCI}
}

@inproceedings{chi2020-EA,
    author = {Shin, Hyunjin and Kim, Bugeun and Gweon, Gahgene},
    title = {Guessing or Solving? Exploring the Use of Motion Features from Educational Game Logs},
    year = {2020},
    month = {April},
    isbn = {9781450368193},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3334480.3383005},
    doi = {10.1145/3334480.3383005},
    lang = en,
    abstract = {A learner's guessing behavior while playing educational games can be a key indicator of her disengagement that impacts learning negatively. To distinguish a learner's guessing behavior from solution behavior, we present an explorative study of using motion features, which represent a learner's finger movements on a tablet screen. Our data was collected from the Missing Number game of KitKit School, a tablet-based math game designed for children from pre-K to grade 2 in elementary school. A total of 5,040 problem solving logs, which were collected from 168 students, were analyzed. A two-sample t-test showed a significant difference between guessing and solution behavior for four groups of motion features that indicate distance, curvedness, complexity, and pause (p&lt;0.001). Additionally, our empirical results showed the possibility of using motion features in automatic detection of guessing behavior. Our best model yielded an accuracy of 0.778 and AUC value of 0.851 by using the random forest classifier.},
    booktitle = {Extended Abstracts of the 2020 {CHI} Conference on Human Factors in Computing Systems},
    pages = {1–8},
    numpages = {8},
    keywords = {touch log, learning analytics, guessing behavior, motion features, educational game},
    location = {Honolulu, HI, USA},
    series = {CHI EA '20},
    note = {#Application:Education}
}

@inproceedings{ept,
    title = "{P}oint to the {E}xpression: {S}olving {A}lgebraic {W}ord {P}roblems using the {E}xpression-{P}ointer {T}ransformer {M}odel",
    author = "Kim, Bugeun  and Ki, Kyung Seo  and Lee, Donggeon  and Gweon, Gahgene",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.emnlp-main.308",
    doi = "10.18653/v1/2020.emnlp-main.308",
    pages = "3768--3779",
    lang = en,
    abstract = "Solving algebraic word problems has recently emerged as an important natural language processing task. To solve algebraic word problems, recent studies suggested neural models that generate solution equations by using {`}Op (operator/operand){'} tokens as a unit of input/output. However, such a neural model suffered two issues: expression fragmentation and operand-context separation. To address each of these two issues, we propose a pure neural model, Expression-Pointer Transformer (EPT), which uses (1) {`}Expression{'} token and (2) operand-context pointers when generating solution equations. The performance of the EPT model is tested on three datasets: ALG514, DRAW-1K, and MAWPS. Compared to the state-of-the-art (SoTA) models, the EPT model achieved a comparable performance accuracy in each of the three datasets; 81.3{\%} on ALG514, 59.5{\%} on DRAW-1K, and 84.5{\%} on MAWPS. The contribution of this paper is two-fold; (1) We propose a pure neural model, EPT, which can address the expression fragmentation and the operand-context separation. (2) The fully automatic EPT model, which does not use hand-crafted features, yields comparable performance to existing models using hand-crafted features, and achieves better performance than existing pure neural models by at most 40{\%}.",
    note = {#BK21TopConf #NLP #MathQA},
    series = {EMNLP '20},
}

@inproceedings{geo,
    title = "Generating Equation by Utilizing Operators : {GEO} model",
    author = "Ki, Kyung Seo  and Lee, Donggeon  and Kim, Bugeun  and Gweon, Gahgene",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics ({COLING})",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.38",
    doi = "10.18653/v1/2020.coling-main.38",
    pages = "426--436",
    lang = en,
    abstract = "Math word problem solving is an emerging research topic in Natural Language Processing. Recently, to address the math word problem-solving task, researchers have applied the encoder-decoder architecture, which is mainly used in machine translation tasks. The state-of-the-art neural models use hand-crafted features and are based on generation methods. In this paper, we propose the GEO (Generation of Equations by utilizing Operators) model that does not use hand-crafted features and addresses two issues that are present in existing neural models: 1. missing domain-specific knowledge features and 2. losing encoder-level knowledge. To address missing domain-specific feature issue, we designed two auxiliary tasks: operation group difference prediction and implicit pair prediction. To address losing encoder-level knowledge issue, we added an Operation Feature Feed Forward (OP3F) layer. Experimental results showed that the GEO model outperformed existing state-of-the-art models on two datasets, 85.1{\%} in MAWPS, and 62.5{\%} in DRAW-1K, and reached comparable performance of 82.1{\%} in ALG514 dataset.",
    note = {#BK21TopConf #NLP #MathQA},
    series = {COLING '20},
}

@article{cvcrm,
    author = "Doh, Young Yim and Kim, Bugeun and Lee, Seul and Gweon, Gahgene",
    title = "The Cyclic Value-Context Reinforcement Model of Problematic Internet Use: Empirical Validation Using a Thematic Analysis of Children's Counseling Data",
    journal = "J Med Internet Res",
    year = "2020",
    month = "Jul",
    day = "14",
    volume = "22",
    number = "7",
    pages = "e17996",
    keywords = "problematic internet use; children; cyclic value context reinforcement model; psychosocial value; environmental context; internet utility",
    abstract = "Background: Research on problematic internet use has focused on devising diagnostic criteria or describing the factors that influence internet overuse. However, a paradigm shift is necessary in studying the phenomenon of increased internet use not just from a pathological point of view but also from a developmental point of view that considers children's behavior of adapting to a technology-oriented society. Objective: In this paper, we propose the Cyclic Value-Context Reinforcement Model (CVCRM) to understand problematic internet use behavior. The purpose of our study was to construct a developmental process model that provides a holistic understanding of problematic internet use behavior of children and to empirically validate the proposed model by conducting a thematic analysis on actual counseling data. Methods: To validate the CVCRM, we conducted thematic analysis using the counseling data from 312 Korean children aged 7-18 years. For the coding process, 7 master's and doctoral student researchers participated as coders, and 2 professors supervised the coding process and results. Results: This project was funded from October 2015 to September 2019 to analyze counseling data from 312 children who participated in counseling sessions during January 2012 to May 2014. Based on the data analysis, we present the CVCRM, which integrates existing theoretical approaches and encompasses the 3 interacting aspects that induce and reinforce problematic internet use in children: psychosocial value, environmental context, and internet utility. Specifically, using counseling data, we empirically ascertained that problematic internet use behavior feeds into children's psychosocial values and environmental contexts, which in turn facilitates problematic internet use in a cyclical manner. Conclusions: Through this empirical validation, the CVCRM can provide a theoretical framework and an integrated perspective on the developmental mechanism of problematic internet use behavior of children. ",
    issn = "1438-8871",
    doi = "10.2196/17996",
    url = "https://www.jmir.org/2020/7/e17996",
    url = "https://doi.org/10.2196/17996",
    url = "http://www.ncbi.nlm.nih.gov/pubmed/32460233",
    note = {#SCIE #Application:Psychiatry},
}


@article{jba2020,
    author = "Bugeun Kim and Seul Lee and Young Yim Doh and Gahgene Gweon",
    title = "Classification of problematic Internet usage types by motives and contexts with elementary and secondary school-aged counseling clients",
    journal = "Journal of Behavioral Addictions",
    year = "2018",
    month = "September",
    publisher = "Akadémiai Kiadó",
    address = "Budapest, Hungary",
    volume = "7",
    number = "3",
    doi = "10.1556/2006.7.2018.90",
    pages = "644 - 653",
    url = "https://akjournals.com/view/journals/2006/7/3/article-p644.xml",
    note = {#SCIE #Application:Psychiatry}
}

@Article{Lee2021,
    author = {Lee, Donggeon and Ki, Kyung Seo and Kim, Bugeun and Gweon, Gahgene},
    title = {TM-generation model: a template-based method for automatically solving mathematical word problems},
    journal = {The Journal of Supercomputing},
    year = {2021},
    month = {Dec},
    day = {01},
    volume = {77},
    number = {12},
    pages = {14583-14599},
    abstract = {In this study, we propose a novel model called template-based multitask generation (TM-generation) that can improve the problem-solving accuracy of mathematical word problem-solving task. In automatic mathematical word problem-solving task, a machine learning model should deduce an answer to a given problem by acquiring implied numeric information. To build a robust model that can sufficiently utilize numeric information to solve various mathematical word problems, such a model should address two challenges: (1) filling in missing world knowledge required to solve the given mathematical word problem, and (2) understanding the implied relationship between numbers and variables. To address these two challenges, we propose template-based multitask generation (TM-generation). To address challenge (1), we utilize the state-of-the-art language models called ELECTRA. To address challenge (2), we propose an operator identification layer that models the relationship between numbers and variables. Our experimental results show that using the MAWPS and Math23k datasets, state-of-the-art performance was achieved: 85.2{\%} in MAWPS and 85.3{\%} in Math23k.},
    issn = {1573-0484},
    doi = {10.1007/s11227-021-03855-9},
    url = {https://doi.org/10.1007/s11227-021-03855-9},
    note = {#SCIE #NLP #MathQA}
}

@inproceedings{kips,
    title = "{K}o{EPT}: Transformer 기반 생성 모델을 사용한 한국어 수학 문장제 문제 자동 풀이",
    author = "Rhim, Sang-kyu and Ki, Kyung Seo and Kim, Bugeun and Gweon, Gahgene",
    booktitle = "Proceedings of the Korea Information Processing Society Conference (한국정보처리학회논문집)",
    month = "May",
    year = "2021",
    address = "Online",
    publisher = "한국정보처리학회",
    lang = ko,
    url = "https://doi.org/10.3745/PKIPS.y2021m05a.362",
    doi = "10.3745/PKIPS.y2021m05a.362",
    pages = "362--365",
    note = {#Domestic #NLP #MathQA},
    series = {한국정보처리학회},
}


@inproceedings{imitation,
    title = "모사학습의 문장형 수학 문제 자동 풀이 적용 가능성 탐구",
    author = "Kim, Bugeun and Gweon, Gahgene",
    booktitle = "한국정보과학회 2021 한국컴퓨터종합학술대회 논문집",
    month = "June",
    year = "2021",
    address = "Online",
    lang = ko,
    publisher = "한국정보과학회",
    url = "https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE10582919",
    pages = "322--324",
    note = {#Domestic #NLP #MathQA},
    series = {한국정보과학회},
}

@inproceedings{eptx,
    title = "{EPT}-{X}: An Expression-Pointer Transformer model that generates e{X}planations for numbers",
    author = "Kim, Bugeun  and Ki, Kyung Seo  and Rhim, Sangkyu  and Gweon, Gahgene",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.acl-long.305",
    doi = "10.18653/v1/2022.acl-long.305",
    pages = "4442--4458",
    abstract = "In this paper, we propose a neural model EPT-X (Expression-Pointer Transformer with Explanations), which utilizes natural language explanations to solve an algebraic word problem. To enhance the explainability of the encoding process of a neural model, EPT-X adopts the concepts of plausibility and faithfulness which are drawn from math word problem solving strategies by humans. A plausible explanation is one that includes contextual information for the numbers and variables that appear in a given math word problem. A faithful explanation is one that accurately represents the reasoning process behind the model{'}s solution equation. The EPT-X model yields an average baseline performance of 69.59{\%} on our PEN dataset and produces explanations with quality that is comparable to human output. The contribution of this work is two-fold. (1) EPT-X model: An explainable neural model that sets a baseline for algebraic word problem solving task, in terms of model{'}s correctness, plausibility, and faithfulness. (2) New dataset: We release a novel dataset PEN (Problems with Explanations for Numbers), which expands the existing datasets by attaching explanations to each number/variable.",
    note = {#BK21TopConf #NLP #MathQA #Explainability},
    series = {ACL '22},
}

@inproceedings{ki-etal-2024-inspecting,
    title = "Inspecting Soundness of {AMR} Similarity Metrics in terms of Equivalence and Inequivalence",
    author = "Ki, Kyung Seo  and
      Kim, Bugeun  and
      Gweon, Gahgene",
    editor = "Bollegala, Danushka  and
      Shwartz, Vered",
    booktitle = "Proceedings of the 13th Joint Conference on Lexical and Computational Semantics (*SEM 2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.starsem-1.32",
    doi = "10.18653/v1/2024.starsem-1.32",
    pages = "402--409",
    abstract = "In this study, we investigate soundness of current Abstract Meaning Representation (AMR) similarity metrics in terms of equivalence and inequivalence. Specifically, AMR guidelines provide several equivalence and inequivalence conditions to reflect the meaning aspect of the semantics. Thus, it is important to examine an AMR metric{'}s soundness, i.e., whether the metric correctly reflects the guidelines. However, the existing metrics have less investigated their soundness. In this work, we propose a new experimental method using simulated data and a series of statistical tests to verify the metric{'}s soundness. Our experimental result revealed that all existing metrics such as Smatch, SemBLEU, S2match, Smatch++, WWLK-theta, WWLK-k3e2n, and SEMA did not fully meet the AMR guidelines in terms of equivalence and inequivalence aspects. Also, to alleviate this soundness problem, we suggest a revised metric called Smatch{\#}, which adopts simple graph standardization technique that can improve the soundness of an existing metric.",
    note = {#NLP #Explainability #SemanticParsing},
    series = {*SEM 2024}
}

@misc{microscopicanalysis,
      title={Microscopic Analysis on LLM players via Social Deduction Game}, 
      author={Byungjun Kim and Dayeon Seo and Bugeun Kim},
      year={2024},
      month=aug,
      eprint={2408.09946},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2408.09946}, 
      doi = "10.48550/arXiv.2408.09946",
      abstract = "Recent studies have begun developing autonomous game players for social deduction games using large language models (LLMs). When building LLM players, fine-grained evaluations are crucial for addressing weaknesses in game-playing abilities. However, existing studies have often overlooked such assessments. Specifically, we point out two issues with the evaluation methods employed. First, game-playing abilities have typically been assessed through game-level outcomes rather than specific event-level skills; Second, error analyses have lacked structured methodologies. To address these issues, we propose an approach utilizing a variant of the SpyFall game, named SpyGame. We conducted an experiment with four LLMs, analyzing their gameplay behavior in SpyGame both quantitatively and qualitatively. For the quantitative analysis, we introduced eight metrics to resolve the first issue, revealing that these metrics are more effective than existing ones for evaluating the two critical skills: intent identification and camouflage. In the qualitative analysis, we performed thematic analysis to resolve the second issue. This analysis identifies four major categories that affect gameplay of LLMs. Additionally, we demonstrate how these categories complement and support the findings from the quantitative analysis.",
      note = {#NLP #LLMbasedAgent}
}
@inproceedings{choi2024peopleagreeithink,
      title={People will agree what I think: Investigating LLM's False Consensus Effect}, 
      author={Junhyuk Choi and Yeseon Hong and Bugeun Kim},
      year={2025},
      month={April},
      address = "Albuquerque, New Mexico",
      booktitle = "Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics",
      publisher = "Nations of the Americas Chapter of the Association for Computational Linguistics",
      eprint={2407.12007},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2407.12007}, 
      doi = "10.48550/arXiv.2407.12007",
      abstract = "Large Language Models (LLMs) have recently been widely adopted on interactive systems requiring communications. As the false belief in a model can harm the usability of such systems, LLMs should not have cognitive biases that humans have. Especially psychologists focused on the False Consensus Effect (FCE), which can distract smooth communication by posing false beliefs. However, previous studies have less examined FCE in LLMs thoroughly, which needs more consideration of confounding biases, general situations, and prompt changes. Therefore, in this paper, we conduct two studies to deeply examine the FCE phenomenon in LLMs. In Study 1, we investigate whether LLMs have FCE. In Study 2, we explore how various prompting styles affect the demonstration of FCE. As a result of these studies, we identified that popular LLMs have FCE. Also, the result specifies the conditions when the strength of FCE becomes larger or smaller compared to normal usage.",
      series = {NAACL Findings '25},
      note = {#NLP #LLMxPsychology}
}
@misc{choi2024doeschatchangellms,
      title={Does chat change LLM's mind? Impact of Conversation on Psychological States of LLMs},
      author={Junhyuk Choi and Yeseon Hong and Minju Kim and Bugeun Kim},
      year={2024},
      month=dec,
      eprint={2412.00804},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2412.00804},
      doi = "10.48550/arXiv.2412.00804",
      abstract="The recent growth of large language models (LLMs) has enabled more authentic, human-centered interactions through multi-agent systems. However, investigation into how conversations affect the psychological states of LLMs is limited, despite the impact of these states on the usability of LLM-based systems. In this study, we explored whether psychological states change during multi-agent interactions, focusing on the effects of conversation depth, topic, and speaker. We experimentally investigated the behavior of 10 LLMs in open-domain conversations. We employed 14 questionnaires and a topic-analysis method to examine the behavior of LLMs across four aspects: personality, interpersonal relationships, motivation, and emotion. The results revealed distinct psychological trends influenced by conversation depth and topic, with significant variations observed between different LLM families and parameter sizes.", 
      note = {#NLP #LLMxPsychology #Agent}
}
@inproceedings{park2024dartaigtdetectorusing,
      title={DART: An AIGT Detector using AMR of Rephrased Text}, 
      author={Hyeonchu Park and Byungjun Kim and Bugeun Kim},
      year={2025},
      month = {April},
      addres = "Albuquerque, New Mexico",
      booktitle = "Annual Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics",
      publisher = "Nations of the Americas Chapter of the Association for Computational Linguistics",
      eprint={2412.11517},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.11517}, 
      doi = "10.48550/arXiv.2412.11517",
      abstract = "As large language models (LLMs) generate more human-like texts, concerns about the side effects of AI-generated texts (AIGT) have grown. So, researchers have developed methods for detecting AIGT. However, two challenges remain. First, the performance on detecting black-box LLMs is low, because existing models have focused on syntactic features. Second, most AIGT detectors have been tested on a single-candidate setting, which assumes that we know the origin of an AIGT and may deviate from the real-world scenario. To resolve these challenges, we propose DART, which consists of four steps: rephrasing, semantic parsing, scoring, and multiclass classification. We conducted several experiments to test the performance of DART by following previous work. The experimental result shows that DART can discriminate multiple black-box LLMs without using syntactic features and knowing the origin of AIGT.",
      series = {NAACL '25},
      note = {#NLP #Application #Detection}
}
@inproceedings{kim2025leveraginglargelanguagemodels,
      title={Leveraging Large Language Models for Active Merchant Non-player Characters}, 
      author={Byungjun Kim and Minju Kim and Dayeon Seo and Bugeun Kim},
      year={2025},
      month = {aug},
      eprint={2412.11189},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2412.11189},
      doi = "10.48550/arXiv.2412.11189",
      abstract = "We highlight two significant issues leading to the passivity of current merchant non-player characters (NPCs): pricing and communication. While immersive interactions have been a focus, negotiations between merchant NPCs and players on item prices have not received sufficient attention. First, we define passive pricing as the limited ability of merchants to modify predefined item prices. Second, passive communication means that merchants can only interact with players in a scripted manner. To tackle these issues and create an active merchant NPC, we propose a merchant framework based on large language models (LLMs), called MART, which consists of an appraiser module and a negotiator module. We conducted two experiments to guide game developers in selecting appropriate implementations by comparing different training methods and LLM sizes. Our findings indicate that finetuning methods, such as supervised finetuning (SFT) and knowledge distillation (KD), are effective in using smaller LLMs to implement active merchant NPCs. Additionally, we found three irregular cases arising from the responses of LLMs. We expect our findings to guide developers in using LLMs for developing active merchant NPCs.",
      series = {IJCAI '25},
      note = {#NLP}

}
@inproceedings{10936883,
        author = { Lee, Yoonjae and Ki, Kyung Seo and Gweon, Gahgene and Kim, Bugeun },
        booktitle = { 2025 IEEE International Conference on Big Data and Smart Computing (BigComp) },
        title = { Examining the Impact of Expression Fragmentation and Number Redundancy on Financial QA task },
        year = {2025},
        volume = {},
        ISSN = {},
        pages = {115-116},
        abstract = { The goal of financial QA is to generate solution equations by solving problems about financial reports. Current financial QA models can suffer from two issues: expression fragmentation and number redundancy. We conduct experiments to examine the impact of the two issues. The experimental results show that addressing the expression fragmentation issue in financial QA using EPT improves the execution accuracy by 0.09, and alleviating the number redundancy issue by removing redundant numbers in the input of the FinQANet generator improves the execution accuracy by 0.07. },
        keywords = {Accuracy;Computational modeling;Redundancy;Big Data;Mathematical models;Generators},
        doi = {10.1109/BigComp64353.2025.00034},
        url = {https://doi.ieeecomputersociety.org/10.1109/BigComp64353.2025.00034},
        publisher = {IEEE Computer Society},
        address = {Los Alamitos, CA, USA},
        month ={Feb},
        series = {BIGCOMP '25},
        note = {#QAtask}  
}
@misc{kim2025phishmeshkoreanadversarial,
      title={PHISH in MESH: Korean Adversarial Phonetic Substitution and Phonetic-Semantic Feature Integration Defense}, 
      author={Byungjun Kim and Minju Kim and Hyeonchu Park and Bugeun Kim},
      year={2025},
      eprint={2505.21380},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      doi = "10.48550/arXiv.2505.21380",
      url={https://arxiv.org/abs/2505.21380},
      abstract = "As malicious users increasingly employ phonetic substitution to evade hate speech detection, researchers have investigated such strategies. However, two key challenges remain. First, existing studies have overlooked the Korean language, despite its vulnerability to phonetic perturbations due to its phonographic nature. Second, prior work has primarily focused on constructing datasets rather than developing architectural defenses. To address these challenges, we propose (1) PHonetic-Informed Substitution for Hangul (PHISH) that exploits the phonological characteristics of the Korean writing system, and (2) Mixed Encoding of Semantic-pHonetic features (MESH) that enhances the detector's robustness by incorporating phonetic information at the architectural level. Our experimental results demonstrate the effectiveness of our proposed methods on both perturbed and unperturbed datasets, suggesting that they not only improve detection performance but also reflect realistic adversarial behaviors employed by malicious users.",
      note = {#HateSpeechDetection #LLM} 
}
@misc{choi2025stereotypecontentanalysiscolorrelated,
      title={A Stereotype Content Analysis on Color-related Social Bias in Large Vision Language Models}, 
      author={Junhyuk Choi and Minju Kim and Yeseon Hong and Bugeun Kim},
      year={2025},
      eprint={2505.20901},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      doi = "10.48550/arXiv.2505.20901",
      url={https://arxiv.org/abs/2505.20901},
      abstract = "As large vision language models(LVLMs) rapidly advance, concerns about their potential to learn and generate social biases and stereotypes are increasing. Previous studies on LVLM's stereotypes face two primary limitations: metrics that overlooked the importance of content words, and datasets that overlooked the effect of color. To address these limitations, this study introduces new evaluation metrics based on the Stereotype Content Model (SCM). We also propose BASIC, a benchmark for assessing gender, race, and color stereotypes. Using SCM metrics and BASIC, we conduct a study with eight LVLMs to discover stereotypes. As a result, we found three findings. (1) The SCM-based evaluation is effective in capturing stereotypes. (2) LVLMs exhibit color stereotypes in the output along with gender and race ones. (3) Interaction between model architecture and parameter sizes seems to affect stereotypes. We release BASIC publicly on [anonymized for review].",
      note = {#LLMxPsychology} 
}
@misc{hong2025llmshumansfriendsuncovering,
      title={Can LLMs and humans be friends? Uncovering factors affecting human-AI intimacy formation}, 
      author={Yeseon Hong and Junhyuk Choi and Minju Kim and Bugeun Kim},
      year={2025},
      eprint={2505.24658},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      doi = "10.48550/arXiv.2505.24658",
      url={https://arxiv.org/abs/2505.24658},
      abstract = "Large language models (LLMs) are increasingly being used in conversational roles, yet little is known about how intimacy emerges in human-LLM interactions. Although previous work emphasized the importance of self-disclosure in human-chatbot interaction, it is questionable whether gradual and reciprocal self-disclosure is also helpful in human-LLM interaction. Thus, this study examined three possible aspects contributing to intimacy formation: gradual self-disclosure, reciprocity, and naturalness. Study 1 explored the impact of mutual, gradual self-disclosure with 29 users and a vanilla LLM. Study 2 adopted self-criticism methods for more natural responses and conducted a similar experiment with 53 users. Results indicate that gradual self-disclosure significantly enhances perceived social intimacy, regardless of persona reciprocity. Moreover, participants perceived utterances generated with self-criticism as more natural compared to those of vanilla LLMs; self-criticism fostered higher intimacy in early stages. Also, we observed that excessive empathetic expressions occasionally disrupted immersion, pointing to the importance of response calibration during intimacy formation.",
      note = {#HCI #NLP #LLMxPsychology} 
}
@misc{choi2025payllmwantsllm,
      title={Pay What LLM Wants: Can LLM Simulate Economics Experiment with 522 Real-human Persona?},
      author={Junhyuk Choi and Hyeonchu Park and Haemin Lee and Hyebeen Shin and Hyun Joung Jin and Bugeun Kim},
      year={2025},
      eprint={2508.03262},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      doi = "10.48550/arXiv.2508.03262",
      url={https://arxiv.org/abs/2508.03262},
      note={#NLP #LLMxPsychology}
}
@inproceedings{voicebbq,
      title={VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model},
      author={Junhyuk Choi and Ro-hoon Oh and Jihwan Seol and Bugeun Kim},
      year={2025},
      month = {aug},
      series = {EMNLP '25},
      archivePrefix={Accepted EMNLP 25 Main},
      abstract = "We introduce VoiceBBQ, a spoken extension of the BBQ benchmark that disentangles bias along two orthogonal axes: content and acoustic. The dataset converts every BBQ context into controlled voice conditions, enabling per-axis accuracy, bias, and consistency scores that remain comparable to the original text benchmark. Using Voice BBQ, we evaluate two SLMs—LLaMA-Omni and Qwen2-Audio—and observe sharp architectural contrasts: LLaMA-Omni retains strong acoustic sensitivity, amplifying gender and accent bias, whereas Qwen2-Audio substantially dampens these cues while preserving content fidelity. Voice BBQ thus provides a compact, drop-in testbed for jointly diagnosing textual and acoustic bias across spoken language models.",
      doi = "10.48550/arXiv.2509.21108",
      url={https://arxiv.org/abs/2509.21108},
      note = {#Bias, #LLMxPsychology, #SLM #BK21TopConf}
}
@misc{genderknowledge,
      title={Acoustic-based Gender Differentiation in Speech-aware Language Models},
      author={Junhyuk Choi and Jihwan Seol and Nayeon Kim and Chanhee Cho and EunBin Cho and Bugeun Kim},
      year={2025},
      eprint={2509.21125},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      abstract ="Speech-aware Language Models (SpeechLMs) have fundamentally transformed human-AI interaction by enabling voice-based communication, yet they may exhibit acoustic-based gender differentiation where identical questions lead to different responses based on the speaker's gender. This paper propose a new dataset that enables systematic analysis of this phenomenon, containing 9,208 speech samples across three categories: Gender-Independent, Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni series and discovered a paradoxical pattern; while overall responses seems identical regardless of gender, the pattern is far from unbiased responses. Specifically, in Gender-Stereotypical questions, all models consistently exhibited male-oriented responses; meanwhile, in Gender-Dependent questions where gender differentiation would be contextually appropriate, models exhibited responses independent to gender instead. We also confirm that this pattern does not result from neutral options nor perceived gender of a voice. When we allow neutral response, models tends to respond neutrally also in Gender-Dependent questions. The paradoxical pattern yet retains when we applied gender neutralization methods on speech. Through comparison between SpeechLMs with corresponding backbone LLMs, we confirmed that these paradoxical patterns primarily stem from Whisper speech encoders, which generates male-oriented acoustic tokens. These findings reveal that current SpeechLMs may not successfully remove gender biases though they prioritized general fairness principles over contextual appropriateness, highlighting the need for more sophisticated techniques to utilize gender information properly in speech technology." ,
      doi = "10.48550/arXiv.2509.21125",
      url={https://arxiv.org/abs/2509.21125},
      note = {"#Bias, #SpeechLMs, #LLMxPsychology}
}      